{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iriMtq7JHQtT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciTgjmS_DUlg"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JWwI7M6wqA3"
      },
      "outputs": [],
      "source": [
        "%pip install gradio pytesseract opencv-python-headless\n",
        "%pip install -qU langchain-groq\n",
        "%pip install -qU json5\n",
        "%pip install langchain\n",
        "%pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lVJgRSGRDVcV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4vQ4yD3KINRr"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "groq_key = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cd-3uKLaIVO0"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    groq_api_key=groq_key,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-Ou0e38XIgPb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json5 as json\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fmb9FQFUIolM"
      },
      "outputs": [],
      "source": [
        "def get_extracted_json(str_data):\n",
        "    # Define the prompt template\n",
        "    template = \"\"\"\n",
        "    You are an assistant that extracts information from invoices. Given the following text input, extract the Customer Name, Invoice No., Invoice Date, and Total Amount. Return the extracted information in a JSON format as shown below:\n",
        "\n",
        "    Input:\n",
        "    {invoice_text}\n",
        "\n",
        "    Output format:\n",
        "    {{\n",
        "      \"Customer Name\": {{\n",
        "        \"value\": \"<Customer Name>\"\n",
        "      }},\n",
        "      \"Invoice No.\": {{\n",
        "        \"value\": \"<Invoice No.>\"\n",
        "      }},\n",
        "      \"Invoice Date\": {{\n",
        "        \"value\": \"<Invoice Date>\"\n",
        "      }},\n",
        "      \"Total Amount\": {{\n",
        "        \"value\": \"<Total Amount>\"\n",
        "      }}\n",
        "    }}\n",
        "\n",
        "    Example Input:\n",
        "    \"Invoice no: 40378170 Date of issue: Seller: Patel, Thompson and Montgomery 356 Kyle Vista New James, MA 46228 Tax Id: 958-74-3511 IBAN: GB77WRBQ31965128414006 ITEMS No. Description Qty 1. Leed's Wine Companion Bottle 1,00 Corkscrew Opener Gift Box Set with Foil Cutter SUMMARY VAT [%] 10% Total 10/15/2012 Client: Jackson, Odonnell and Jackson 267 John Track Suite 841 Jenniferville, PA 98601 Tax Id: 998-87-7723 UM Net price Net worth VAT [%] each 7,50 7,50 10% Net worth VAT 7,50 0,75 $ 7,50 $ 0,75 Gross worth 8,25 Gross worth 8,25 $ 8,25\"\n",
        "\n",
        "    Example Output:\n",
        "    {{\n",
        "      \"Customer Name\": {{\n",
        "        \"value\": \"Jackson, Odonnell and Jackson\"\n",
        "      }},\n",
        "      \"Invoice No.\": {{\n",
        "        \"value\": \"40378170\"\n",
        "      }},\n",
        "      \"Invoice Date\": {{\n",
        "        \"value\": \"10/15/2012\"\n",
        "      }},\n",
        "      \"Total Amount\": {{\n",
        "        \"value\": \"$ 8,25\"\n",
        "      }}\n",
        "    }}\n",
        "\n",
        "    Now, provide the output for the given input.\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"invoice_text\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    invoice_text = str_data\n",
        "    result = chain.run(invoice_text=invoice_text)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VXL5gDzrIunn"
      },
      "outputs": [],
      "source": [
        "def extract_json(text):\n",
        "  \"\"\"Extracts JSON data from a text string.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text string containing the JSON data.\n",
        "\n",
        "    Returns:\n",
        "        dict: The parsed JSON data as a dictionary.\n",
        "\n",
        "    Raises:\n",
        "        json.JSONDecodeError: If the JSON data is invalid.\n",
        "    \"\"\"\n",
        "\n",
        "  start = text.find('{')\n",
        "  end = text.rfind('}') + 1\n",
        "  json_string = text[start:end]\n",
        "  return json.loads(json_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "buGLsGjII0Y9"
      },
      "outputs": [],
      "source": [
        "def update_json(json_data, coordinates):\n",
        "  \"\"\"Updates a JSON object with coordinate information.\n",
        "\n",
        "  Args:\n",
        "    json_data: The JSON object to be updated.\n",
        "    coordinates: A dictionary mapping values to their corresponding coordinates.\n",
        "\n",
        "  Returns:\n",
        "    The updated JSON object.\n",
        "  \"\"\"\n",
        "  updated_json = {}\n",
        "  for key, value in json_data.items():\n",
        "    updated_value = value.copy()\n",
        "    if key != 'Invoice No.':\n",
        "      updated_value['coordinate'] = coordinates.get(value['value'], \"NA\")\n",
        "    else:\n",
        "      invoice = f\"Invoice no: {value['value']}\"\n",
        "      updated_value['coordinate'] = coordinates.get(invoice, \"NA\")\n",
        "    updated_json[key] = updated_value\n",
        "  return updated_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fnqwcVjaG9-R"
      },
      "outputs": [],
      "source": [
        "def ocr_using_teseract(image):\n",
        "    \"\"\"\n",
        "    Extracts text from an image using Tesseract OCR.\n",
        "\n",
        "    Args:\n",
        "        image: The input image.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, where each dictionary represents a paragraph extracted from the image.\n",
        "        Each dictionary contains two keys:\n",
        "            - `coordinates`: A list of four integers representing the bounding box coordinates (x1, y1, x2, y2) of the paragraph.\n",
        "            - `text`: The extracted text from the paragraph.\n",
        "    \"\"\"\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "\n",
        "    paragraphs = []\n",
        "    current_paragraph = {'coordinates': [float('inf'), float('inf'), 0, 0], 'text': \"\"}\n",
        "\n",
        "    for i in range(len(data['text'])):\n",
        "        text = data['text'][i].strip()\n",
        "        if text and int(data['conf'][i]) > 0:\n",
        "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "            current_paragraph['coordinates'][0] = min(current_paragraph['coordinates'][0], x)  # x1\n",
        "            current_paragraph['coordinates'][1] = min(current_paragraph['coordinates'][1], y)  # y1\n",
        "            current_paragraph['coordinates'][2] = max(current_paragraph['coordinates'][2], x + w)  # x2\n",
        "            current_paragraph['coordinates'][3] = max(current_paragraph['coordinates'][3], y + h)  # y2\n",
        "            current_paragraph['text'] += \" \" + text\n",
        "\n",
        "            if i < len(data['text']) - 1:\n",
        "                next_y = data['top'][i + 1]\n",
        "                if abs(next_y - y) > 10:\n",
        "                    paragraphs.append(current_paragraph)\n",
        "                    current_paragraph = {'coordinates': [float('inf'), float('inf'), 0, 0], 'text': \"\"}\n",
        "\n",
        "    if current_paragraph['text']:\n",
        "        paragraphs.append(current_paragraph)\n",
        "    return paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qLzQMZeAHJ_p"
      },
      "outputs": [],
      "source": [
        "def get_context(paragraphs):\n",
        "    \"\"\"\n",
        "    Extracts context and coordinates from a list of paragraphs.\n",
        "\n",
        "    Args:\n",
        "        paragraphs (list): A list of dictionaries, each containing 'text' and 'coordinates' of a paragraph.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - The concatenated text of all paragraphs.\n",
        "            - A dictionary mapping paragraph text to its coordinates.\n",
        "    \"\"\"\n",
        "    context = \"\"\n",
        "    dict_of_paragraphs = {}\n",
        "    for idx, para in enumerate(paragraphs):\n",
        "        para_text = para['text'].strip()\n",
        "        coordinates = para['coordinates']\n",
        "        # context += f\"Paragraph {idx + 1}:\\n{para_text}\\nCoordinates: {coordinates}\\n\\n\"\n",
        "        dict_of_paragraphs[para_text] = coordinates\n",
        "        context += f\"{para_text} \\t\\t\"\n",
        "    return context, dict_of_paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "OPtvMHBFPVRT",
        "outputId": "59599fc3-8e50-4ce8-a820-43dca0a46af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://77525079127e49245f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://77525079127e49245f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def ocr_with_bounding_boxes(image: np.ndarray):\n",
        "    \"\"\"Performs OCR on the given image and draws bounding boxes around detected text.\n",
        "\n",
        "    Args:\n",
        "        image: A NumPy array representing the image to be processed.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "            - The processed image with bounding boxes drawn.\n",
        "            - A JSON string representing the extracted text and their coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    open_cv_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    data = ocr_using_teseract(open_cv_image)\n",
        "\n",
        "    context, dict_of_paragraphs = get_context(data)\n",
        "    json_result = get_extracted_json(context)\n",
        "    json_data = extract_json(json_result)\n",
        "    updated_json = update_json(json_data, dict_of_paragraphs)\n",
        "    print(updated_json)\n",
        "\n",
        "    for key, value in updated_json.items():\n",
        "        coords = value['coordinate']\n",
        "        extracted_text = key\n",
        "\n",
        "        cv2.rectangle(open_cv_image, (coords[0], coords[1]), (coords[2], coords[3]), color=(255, 0, 0), thickness=2)\n",
        "\n",
        "        text_position = (coords[0], coords[1] - 20)\n",
        "        cv2.putText(open_cv_image, extracted_text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    result_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2RGB)\n",
        "    json_output = json.dumps(updated_json, indent=4)\n",
        "    return result_image, json_output\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=ocr_with_bounding_boxes,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=[gr.Image(type=\"numpy\"), gr.Textbox(label=\"Extracted JSON\")],\n",
        "    title=\"OCR with Bounding Boxes and Text Extraction\",\n",
        "    description=\"Upload an image to extract text using OCR and visualize bounding boxes.\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9VZsrvYQfpx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
